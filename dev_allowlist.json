{
  "models": [
    {
      "name": "Gemma-3n-E2B-it",
      "modelId": "google/gemma-3n-E2B-it-litert-lm",
      "modelFile": "gemma-3n-E2B-it-int4.litertlm",
      "description": "Preview version of [Gemma 3n E2B](https://ai.google.dev/gemma/docs/gemma-3n) ready for deployment on iOS using the [MediaPipe LLM Inference API](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference). The current checkpoint suppots text, vision, and audio input, with 4096 context length.",
      "sizeInBytes": 3388604416,
      "minDeviceMemoryInGb": 6,
      "commitHash": "73b019b63436d346f68dd9c1dbfd117eb264d888",
      "llmSupportImage": true,
      "llmSupportAudio": true,
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "gpu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab", "llm_ask_image", "llm_ask_audio"],
      "bestForTaskTypes": ["llm_ask_image", "llm_ask_audio"]
    },
    {
      "name": "Gemma-3n-E4B-it",
      "modelId": "google/gemma-3n-E4B-it-litert-lm",
      "modelFile": "gemma-3n-E4B-it-int4.litertlm",
      "description": "Preview version of [Gemma 3n E4B](https://ai.google.dev/gemma/docs/gemma-3n) ready for deployment on iOS using the [MediaPipe LLM Inference API](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference). The current checkpoint supports text, vision, and audio input, with 4096 context length.",
      "sizeInBytes": 4652318720,
      "minDeviceMemoryInGb": 8,
      "commitHash": "3d0179a0648381585ab337e170b7517aae8e0ce4",
      "llmSupportImage": true,
      "llmSupportAudio": true,
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "gpu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab", "llm_ask_image", "llm_ask_audio"]
    },
    {
      "name": "Gemma3-1B-IT",
      "modelId": "litert-community/Gemma3-1B-IT",
      "modelFile": "gemma3-1b-it-int4.litertlm",
      "description": "A variant of [google/Gemma-3-1B-IT](https://huggingface.co/google/Gemma-3-1B-IT) with 4-bit quantization ready for deployment on iOS using the [MediaPipe LLM Inference API](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference)",
      "sizeInBytes": 584417280,
      "minDeviceMemoryInGb": 6,
      "commitHash": "42d538a932e8d5b12e6b3b455f5572560bd60b2c",
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "cpu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab"],
      "bestForTaskTypes": ["llm_chat", "llm_prompt_lab"]
    },
    {
      "name": "Gemma-3n-E2B-it-Converted",
      "modelId": "google/gemma-3n-E2B-it-litert-lm",
      "modelFile": "gemma-3n-E2B-it-int4.litertlm",
      "description": "Preview version of [Gemma 3n E2B](https://ai.google.dev/gemma/docs/gemma-3n) ready for deployment on iOS using the [MediaPipe LLM Inference API](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference). The current checkpoint suppots text, vision, and audio input, with 4096 context length.",
      "sizeInBytes": 3388604416,
      "minDeviceMemoryInGb": 6,
      "commitHash": "ba9ca88da013b537b6ed38108be609b8db1c3a16",
      "llmSupportImage": true,
      "llmSupportAudio": true,
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "cpu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab", "llm_ask_image", "llm_ask_audio"],
      "bestForTaskTypes": ["llm_ask_image", "llm_ask_audio"]
    },
    {
      "name": "Gemma-3n-E4B-it-Converted",
      "modelId": "google/gemma-3n-E4B-it-litert-lm",
      "modelFile": "gemma-3n-E4B-it-int4.litertlm",
      "description": "Preview version of [Gemma 3n E4B](https://ai.google.dev/gemma/docs/gemma-3n) ready for deployment on iOS using the [MediaPipe LLM Inference API](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference). The current checkpoint supports text, vision, and audio input, with 4096 context length.",
      "sizeInBytes": 4652318720,
      "minDeviceMemoryInGb": 8,
      "commitHash": "297ed75955702dec3503e00c2c2ecbbf475300bc",
      "llmSupportImage": true,
      "llmSupportAudio": true,
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "cpu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab", "llm_ask_image", "llm_ask_audio"]
    },
    {
      "name": "Gemma-3n-E2B-old-task",
      "modelId": "google/gemma-3n-E2B-it-litert-preview",
      "modelFile": "gemma-3n-E2B-it-int4.task",
      "description": "Preview version of [Gemma 3n E2B](https://ai.google.dev/gemma/docs/gemma-3n) ready for deployment on iOS using the [MediaPipe LLM Inference API](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference). The current checkpoint supports text, vision, and audio input, with 4096 context length.",
      "sizeInBytes": 3136226711,
      "minDeviceMemoryInGb": 8,
      "commitHash": "66c93e118deff9961db659f241678e61b847d165",
      "llmSupportImage": true,
      "llmSupportAudio": true,
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "cpu, gpu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab", "llm_ask_image", "llm_ask_audio"]
    },
    {
      "name": "Gemma-3n-E4B-old-task",
      "modelId": "google/gemma-3n-E4B-it-litert-preview",
      "modelFile": "gemma-3n-E4B-it-int4.task",
      "description": "Preview version of [Gemma 3n E4B](https://ai.google.dev/gemma/docs/gemma-3n) ready for deployment on iOS using the [MediaPipe LLM Inference API](https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference). The current checkpoint supports text, vision, and audio input, with 4096 context length.",
      "sizeInBytes": 4405655031,
      "minDeviceMemoryInGb": 8,
      "commitHash": "1bb9b9c34cfe96536b5540699ffa07060e9fa124",
      "llmSupportImage": true,
      "llmSupportAudio": true,
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "cpu, gpu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab", "llm_ask_image", "llm_ask_audio"]
    }
  ]
}
